---
title: Generate JSON Node

description: The Generate JSON Node allows users to generate structured JSON data using AI models with predefined schemas.
type: AI
order: 2
---

import { NodeOverview } from "@/components/NodeOverview";
import { NodeTypeInfo } from "@/components/NodeTypeInfo";

# Generate JSON Node

<NodeOverview slug="generate-json-node" type="ai" />

## Overview

The Generate JSON Node is a specialized AI component that generates structured JSON data based on user input and predefined schemas. This node is particularly useful for applications requiring consistent data structures, API integrations, and automated data formatting.

![json-gen.png](../img/json/json.webp)

<NodeTypeInfo 
  batchTrigger={false}
  eventTrigger={false}
  action={true}
  description="This node is an Action node that processes input data and generates structured JSON output based on predefined schemas."
/>

## Features

<details>
  <summary>Key Functionalities</summary>

1. **Generative Model Selection**: Allows users to select credentials for their preferred generative model, ensuring flexibility and compatibility with various LLMs.

2. **Customizable Prompts**: Features a field for creating prompt templates, enabling tailored input for specific use cases.

3. **System Prompt Definition**: Includes an option to define a system-level prompt to guide the AI's behavior, ensuring context-aware and role-specific responses.

4. **Additional Properties Management**: Offers expandable sections for configuring advanced properties to fine-tune AI-generated outputs.

</details>

<details>
  <summary>Benefits</summary>

1. **Flexibility**: Supports integration with multiple LLMs, allowing users to utilize different models based on their specific needs and use cases.

2. **User-Centric Design**: Provides intuitive interfaces for prompt customization and system prompt definition, making it accessible to both beginners and advanced users.

3. **Enhanced Control**: Enables precise control over the AI's behavior and output quality through customizable prompts and system configurations.

4. **Scalability**: Facilitates the creation of reusable prompt templates for diverse flow, ensuring consistency across projects.

</details>

## What can I build?

1. Create AI-driven applications that require structured data output from natural language inputs.
1. Develop automated systems for generating specific data formats for use in analytics and reporting.
1. Build interactive tools that convert conversational inputs into structured JSON for use in various applications.
1. Design flow for content generation that require consistency in data formatting across different platforms.

## Setup

### Select the JSON Generate Node

1. Fill in the required parameters.
1. Build the desired flow
1. Deploy the Project
1. Click Setup on the workflow editor to get the automatically generated instruction and add it in your application.

## Configuration Reference

| **Parameter**                | **Description**                                                                                                | **Example Value**                     |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------- | ------------------------------------- |
| **Generative Model Name**    | Select the model to generate text based on the prompt.                                                         | Gemini Model                          |
| **Output Schema (Zod JSON)** | Define the output structure and validation rules using Zod JSON.                                               | JSON Schema                           |
| **User Prompt**              | Define the instructions for generating the text output.Define the instructions for generating the text output. | Tell me travel from Bali to Singapore |
| **System Prompt**            | System prompt to guide the LLM                                                                                 | You are Travel Planner                |

## Low-Code Example

```yaml
nodes:
  - nodeId: InstructorLLMNode_774
    nodeType: InstructorLLMNode
    nodeName: JSON Generator
    values:
      schema: |-
        {
          "type": "object",
          "properties": {
            "output": {
              "type": "string"
            }
          }
        }
      promptTemplate: tell me something about ${{triggerNode_1.output.topic}}
      attachments: "[]"
      messages: "[]"
      generativeModelName:
        provider_name: mistral
        type: generator/text
        credential_name: Mistral API
        credentialId: 32bf5e3b-a8fc-4697-b95a-b1af3dcf7498
        model_name: mistral/mistral-large-2402
    needs:
      - triggerNode_1
```

## Output Schema

#### `_meta`

- A nested object containing metadata about the processing of the generation request.

#### Token Usage Details

- **`prompt_tokens`**: Number of tokens in the input prompt provided to the model.
- **`completion_tokens`**: Number of tokens in the generated output.
- **`total_tokens`**: Sum of `prompt_tokens` and `completion_tokens`.

#### `prompt_tokens_details`

- A nested object providing a breakdown of token usage in the prompt.
  - **`cached_tokens`**: Number of tokens reused from a cache.
  - **`audio_tokens`**: Number of tokens associated with audio input (if applicable).

#### `completion_tokens_details`

- A nested object detailing token usage in the generated output.
  - **`reasoning_tokens`**: Number of tokens used for reasoning processes (if applicable).
  - **`audio_tokens`**: Number of tokens associated with audio output (if applicable).
  - **`accepted_prediction_tokens`**: Number of tokens from accepted predictions (if applicable).
  - **`rejected_prediction_tokens`**: Number of tokens from rejected predictions (if applicable).

#### Model Information

- **`model_name`**: The name of the AI model used for generation.
- **`model_provider`**: The provider or organization supplying the model.

### Example Output

```json
{
  "name": "Adelaide",
  "_meta": {
    "prompt_tokens": 56,
    "completion_tokens": 7,
    "total_tokens": 63,
    "prompt_tokens_details": {
      "cached_tokens": 0,
      "audio_tokens": 0
    },
    "completion_tokens_details": {
      "reasoning_tokens": 0,
      "audio_tokens": 0,
      "accepted_prediction_tokens": 0,
      "rejected_prediction_tokens": 0
    },
    "model_name": "gpt-4-turbo",
    "model_provider": "openai"
  }
}
```

## Troubleshooting

### Common Issues

| **Problem**                    | **Solution**                                                 |
| ------------------------------ | ------------------------------------------------------------ |
| **Invalid API Key**            | Ensure the API key is correct and has not expired.           |
| **Dynamic Content Not Loaded** | Increase the `Wait for Page Load` time in the configuration. |

### Debugging

1. Check Lamatic Flow logs for error details.
1. Verify API Key.
