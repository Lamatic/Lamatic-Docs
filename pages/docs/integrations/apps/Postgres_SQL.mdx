---
title: PostgresSQL
description:
---

# PostgresSQL

This node automates data synchronization from a PostgreSQL database by fetching rows from a specified PostgreSQL table at scheduled intervals. It supports row vectorization and RAG (Retrieval-Augmented Generation) by vectorizing and indexing contextual data found within each row.

## What can I build? 
- Automate the regular fetching and synchronization of rows from specified PostgreSQL database table.
- Support the vectorization and indexing of PostgreSQL rows to provide context for RAG flows.

## Available Functionality
### Batch Trigger
✅ Fetch a PostgreSQL table on a scheduled interval. This is the first step in flows that vectorize and store contextual data found in each row of a PostgreSQL table to support subsequent RAG requests. Note: only Tables and Materialized Views are compatible with this trigger function.

### Event Trigger
❌ When a PostgreSQL record is inserted / updated / deleted\
❌ When a PostgreSQL table is created / updated / deleted

### Actions
❌ Add / update / delete a row in a linked PostgreSQL table\
❌ Create / update / delete a linked PostgreSQL table

## Install
### Create a Flow in Lamatic
To set up a flow in Lamatic with a webhook trigger, follow these steps to obtain the necessary webhook configurations.
#### Implementation Options:
1. Create a Custom Flow
        1. Follow our comprehensive webhook integration guide.
        1. Learn how to configure webhooks as trigger events.
        1. Set up custom actions based on incoming webhook data.
1. Use a Pre-built Template
        1. Start with our ready-to-use webhook template.
        1. Quickly implement common webhook scenarios.
        1. Customize the template to suit your specific needs.


##### Important Note:
Always test the webhook endpoint before deploying it in a production environment. For detailed instructions, refer to our documentation or explore our template library.

### Github Action
1. Setup GitHub Secrets: Store sensitive data such as `WEBHOOK_URL` and `WEBHOOK_KEY` in your repository secrets.
1. Create a github action: Add the following YAML to a GitHub Actions workflow file, such as `.github/workflows/lamatic-index-flow.yml`

## Configuration
### Batch Trigger
1. Name - Display name for the node. [nodeName]
1. Credentials - Select existing or click +Add Credentials to provide PostgreSQL authentication details required to connect to the desired PostgreSQL database (Credential Display Name, Host, Port, Database Name, Username, Password). [credentials]
1. Schema - Select the schema that describes the database to be processed. [schemas]
1. Table/View - Select the table containing the data to be processed. [tables]
1. Additional Properties:
        1. Sync Mode - Save tokens and only process data that has been updated since last run by selecting Incremental or select Full Refresh to clear your vector database of old records and reprocess all data with the current flow (e.g., embedding model, table structure, etc.). [syncMode]
        1. Sync Schedule - Specify the frequency with which the flow will run using a Cron scheduler. [cronExpression]
1. Sample Data - Click Fetch to see the data returned from the first row in the connected PostgreSQL Table. [n/a]

#### LowCode Config
```js
// Trigger Config Illustration
{
  "triggerNode": {
    "nodeId": "triggerNode_1",
    "nodeType": "postgresNode",
    "nodeName": "Postgres",
    "values": {
      "tables": "Behavior",
      "schemas": "public",
      "syncMode": "incremental_append",
      "credentials": "{your-postgres-credentials}",
      "cronExpression": "0 0 0/1 1/1 * ? * UTC"
    }
  }
}
```
