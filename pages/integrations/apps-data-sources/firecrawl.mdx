---
title: Firecrawl
description: Firecrawl is a robust tool designed to transform websites into LLM-ready data by leveraging its **Crawler** and **Scraper** functionalities. Whether you need to map website structures or extract specific data, Firecrawl provides a seamless and customizable solution.
icon: /images/icons/apps/firecrawl.png
---

import { IntegrationOverviw } from "@/components/IntegrationOverviw"

# Firecrawl Integration

<IntegrationOverviw slug="firecrawl" type="apps-data-sources" />

## Overview
Firecrawl is a robust tool designed to transform websites into LLM-ready data by leveraging its **Crawler** and **Scraper** functionalities. Whether you need to map website structures or extract specific data, Firecrawl provides a seamless and customizable solution.

<Callout type="warning" >
Firecrawl nodes can now be used directly inside sync or async nodes. You no longer need to create a separate flow for crawling or scraping.
</Callout>

## Features

### ✅ Key Functionalities
- **Web Crawling**: Systematically browse and index websites, discovering and mapping their structure.
- **Web Scraping**: Extract targeted content from specific web pages using customizable rules.
- **Integration with Webhooks**: Receive real-time updates about crawling and scraping activities.
- **Dynamic Content Handling**: Support for waiting on dynamic page loads and simulating mobile devices.

### ✅ Benefits
- Generate structured data for language models.
- Customize inclusion and exclusion of website sections.
- Handle both static and dynamic web content.

## Prerequisites

Before using Firecrawl, ensure the following:

- A valid [Firecrawl API Key](https://www.firecrawl.dev/).
- Access to the Firecrawl service host URL.
- Properly configured credentials for Firecrawl.
- A webhook endpoint for receiving notifications (required for the crawler).

<Callout type="warning">  
For Self Hosting,If the connection fails, whitelist the following IPs: [https://www.cloudflare.com/ips/](https://www.cloudflare.com/ips/)
</Callout>

## Setup

### Step 1: Obtain API Credentials
1. Register on [Firecrawl](https://www.firecrawl.dev/).
2. Generate an API key from your account dashboard.
3. Note the **Host URL** and **Webhook Endpoint**.

### Step 2: Configure Firecrawl Credentials
Use the following format to set up your credentials:

| **Key Name**         | **Description**                                         | **Example Value**                |
|-----------------------|---------------------------------------------------------|-----------------------------------|
| **Credential Name**   | Name to identify this set of credentials                | `my-firecrawl-creds`             |
| **Firecrawl API Key** | Authentication key for accessing Firecrawl services     | `fc_api_xxxxxxxxxxxxx`           |
| **Host**              | Base URL where Firecrawl service is hosted             | `https://api.firecrawl.dev`      |


## Configuration Reference

Firecrawl supports two execution modes:

1. **Synchronous (Sync) Mode**
2. **Asynchronous (Async) Mode**

---

In **Async mode**, Firecrawl runs the operation in the background and sends a notification to your configured webhook when complete.
The async mode has the two modes : 
- **Single**: For single URL operations (crawler or scraper).
- **Batch**: For multiple URLs, allowing you to process a list of URLs in one go. Here, you would need to provide **URL List** instead of a single URL.

In **Sync mode**, Firecrawl performs the operation in real-time and returns the result directly in the response.
The sync mode has the two modes:
- **Single**: For single URL operations (crawler or scraper).
- **Batch**: For multiple URLs, allowing you to process a list of URLs in one go. Here, you would need to provide **URL List** instead of a single URL.

---

### Sync Mode Configuration

| **Parameter**         | **Description**                                                  | **Example Value**                 |
|------------------------|------------------------------------------------------------------|-----------------------------------|
| Credential Name        | Select previously saved credentials                              | `my-firecrawl-creds`              |
| URL                    | Starting URL (for crawler) or target URL (for scraper)           | `https://example.com`             |
| Main Content           | Extract only primary page content                                | `true`                            |
| Include Tags           | HTML tags to include (scraper only)                              | `p, h1, h2`                        |
| Exclude Tags           | HTML tags to exclude (scraper only)                              | `nav, footer`                     |
| Include Path           | Paths to include in crawl (crawler only)                         | `"blog/*"`                        |
| Exclude Path           | Paths to exclude in crawl (crawler only)                         | `"admin/*"`                       |
| Crawl Depth            | Maximum crawl depth from start URL                               | `3`                               |
| Crawl Limit            | Maximum number of pages to crawl                                 | `1000`                            |
| Allow External Links   | Allow crawler to follow links to other domains                   | `false`                           |
| Allow Backward Links   | Allow links that point backward in structure                     | `true`                            |
| Crawl Sub Pages        | Enable crawling of sub-pages                                     | `true`                            |
| Ignore Sitemap         | Skip sitemap.xml parsing                                         | `false`                           |
| Wait for Page Load     | Time (in ms) to wait for dynamic content (scraper only)          | `200`                             |
| Emulate Mobile Device  | Simulate a mobile browser environment                            | `true`                            |

#### Sync Mode Output Format

```json
{
  "success": true,
  "status": "completed",
  "completed": 48,
  "total": 50,
  "creditsUsed": 13,
  "expiresAt": "2025-08-01T12:30:00.000Z",
  "data": [
    {
      "url": "https://example.com/page-1",
      "content": "Lorem ipsum dolor sit amet...",
      "metadata": {
        "title": "Page 1 Title",
        "description": "This is a sample description.",
        "language": "en"
      }
    },
    {
      "url": "https://example.com/page-2",
      "content": "Second page scraped content...",
      "metadata": {
        "title": "Page 2 Title",
        "description": "Another sample description.",
        "language": "en"
      }
    }
    // ... more pages
  ]
}
```

### Async Mode Configuration

In case of async mode, the user will have the option to choose the following configurations:

| Parameter          | Description                                           | Example Value                              |
|--------------------|-------------------------------------------------------|--------------------------------------------|
| Credential Name     | Select previously saved credentials                   | `my-firecrawl-creds`                        |
| Callback Webhook    | URL to receive notifications about crawl completion   | `https://example.com/webhook`              |
| Webhook Headers     | Headers to be sent to the webhook                     | `{'Content-Type:application/json'}`        |
| Webhook Metadata    | Metadata to be sent to the webhook                    | `{'status':'{{codeNode_540.status}}'}`     |
| Webhook Events      | A multiselect list of events to be sent to the webhook| `["completed", "failed", "page", "started"]` |

<br/>

#### Async Mode Output Format

```json
{
  "success": true,
  "id": "8***************************7",
  "url": "https://api.firecrawl.dev/v1/crawl/8***************************7"
}
```

### Crawler Configuration (Single)

| **Parameter**            | **Description**                                                   | **Example Value**                 |
|--------------------------|-------------------------------------------------------------------|----------------------------------|
| Credential Name          | Select previously saved credentials                               | `my-firecrawl-creds`             |
| URL                      | Starting point URL for the crawler                                | `https://example.com`            |
| Exclude Path             | URL patterns to exclude from the crawl                            | `"admin/*", "private/*"`         |
| Include Path             | URL patterns to include in the crawl                              | `"blog/*", "products/*"`         |
| Crawl Depth              | Maximum depth to crawl relative to the entered URL                | `3`                              |
| Crawl Limit              | Maximum number of pages to crawl                                  | `1000`                           |
| Crawl Sub Pages          | Toggle to enable or disable crawling sub pages                    | `true`                           |
| Max Discovery Depth      | Max depth for discovering new URLs during the crawl               | `5`                              |
| Ignore Sitemap           | Ignore the sitemap.xml file for crawling                          | `false`                          |
| Allow Backward Links     | Allow crawling backward links (e.g., blog post → homepage)        | `true`                           |
| Allow External Links     | Allow crawling external links (e.g., links to other domains)      | `false`                          |
| Ignore Query Parameters  | Ignore specific query parameters in URLs                          | `false`                          |
| Delay                    | Delay between requests to avoid overloading server (in seconds)   | `2`                              |

---

### Batch Crawler Configuration (Async / Sync)

| **Parameter**         | **Description**                                                         | **Example Value**                      |
|-----------------------|-------------------------------------------------------------------------|----------------------------------------|
| Credential Name       | Select previously saved credentials                                     | `my-firecrawl-creds`                   |
| URL List              | List of starting URLs to crawl                                          | `[ "https://x.com", "https://y.com" ]` |
| Include Path          | Paths to include during crawl                                           | `"blog/*"`                             |
| Exclude Path          | Paths to exclude during crawl                                           | `"admin/*"`                            |
| Crawl Depth           | Depth to crawl for each URL                                             | `3`                                    |
| Crawl Limit           | Max pages per domain                                                    | `500`                                  |
| Max Discovery Depth   | How far discovered links can go                                         | `4`                                    |
| Allow External Links  | Whether to crawl external domains                                       | `false`                                |
| Allow Backward Links  | Whether to revisit previous pages                                       | `true`                                 |
| Crawl Sub Pages       | Enable sub-page traversal                                               | `true`                                 |
| Ignore Sitemap        | Skip sitemap.xml                                                        | `false`                                |
| Delay                 | Throttle request delay in seconds                                       | `1`                                    |

---

### Scraper Configuration (Single)

| **Parameter**         | **Description**                                                         | **Example Value**            |
|-----------------------|-------------------------------------------------------------------------|------------------------------|
| Credential Name       | Select previously saved credentials                                     | `my-firecrawl-creds`         |
| URL                   | Target URL to scrape                                                    | `https://example.com/page`   |
| Main Content          | Extract only main content (exclude header/footer/nav)                   | `true`                       |
| Skip TLS Verification | Bypass SSL certificate validation                                       | `false`                      |
| Include Tags          | HTML tags to include in extraction                                      | `p, h1, h2, article`         |
| Exclude Tags          | HTML tags to exclude from extraction                                    | `nav, footer, aside`         |
| Emulate Mobile Device | Simulate mobile browser access                                          | `true`                       |
| Wait for Page Load    | Time to wait for dynamic content (in ms)                                | `123`                        |

---

### Batch Scraper Configuration (Async)

| **Parameter**         | **Description**                                                         | **Example Value**                      |
|-----------------------|-------------------------------------------------------------------------|----------------------------------------|
| Credential Name       | Select previously saved credentials                                     | `my-firecrawl-creds`                   |
| URL List              | List of URLs to scrape in batch                                         | `[ "https://a.com", "https://b.com" ]` |
| Main Content          | Extract only main content from each page                                | `true`                                 |
| Skip TLS Verification | Ignore SSL certificate errors                                           | `false`                                |
| Include Tags          | HTML tags to extract                                                    | `p, h1, h2`                             |
| Exclude Tags          | HTML tags to exclude from extraction                                    | `aside, footer`                        |
| Emulate Mobile Device | Use mobile browser viewport                                              | `true`                                 |
| Wait for Page Load    | Delay for dynamic content to appear (in ms)                             | `200`                                  |


### Map URL Configuration
| **Parameter**         | **Description**                                                         | **Example Value**                 |
|-----------------------|-------------------------------------------------------------------------|-----------------------------------|
| Credential Name       | Select previously saved credentials                                     | `my-firecrawl-creds`              |
| URL                   | Starting URL to map the structure                                       | `https://example.com`             |
| Main Content          | Extract only main content from each page                                | `true`                                 |
| Skip TLS Verification | Ignore SSL certificate errors                                           | `false`                                |
| Include Tags          | HTML tags to extract                                                    | `p, h1, h2`                             |
| Exclude Tags          | HTML tags to exclude from extraction                                    | `aside, footer`                        |
| Emulate Mobile Device | Use mobile browser viewport                                              | `true`                                 |
| Wait for Page Load    | Delay for dynamic content to appear (in ms)                             | `200`                                  |

### Troubleshooting

#### Common Issues

| **Problem**                 | **Solution**                                                                 |
|-----------------------------|------------------------------------------------------------------------------|
| Invalid API Key             | Ensure the API key is correct and has not expired.                          |
| Connection Issues           | Verify that the host URL is correct and reachable.                          |
| Webhook Errors              | Check if the webhook endpoint is active and correctly configured.           |
| Crawling Errors             | Review the inclusion/exclusion paths for accuracy.                          |
| Dynamic Content Not Loaded  | Increase the `Wait for Page Load` time in the configuration.                |

---

#### Debugging

- Check **Firecrawl logs** for detailed error information.
- Test the **webhook endpoint** to confirm it is receiving updates.
- If the connection fails, whitelist the following IPs: [https://www.cloudflare.com/ips/](https://www.cloudflare.com/ips/)