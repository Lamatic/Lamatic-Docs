---
title: Text Agent
description: The Text Agent in Lamatic.ai generates dynamic text outputs using customizable prompts and LLM models.
---

# **Text Agent**

The **Text Agent** is a generative AI agent that enables users to programmatically create text-based outputs using prompts and selected LLMs. It is ideal for applications requiring dynamic content generation, such as chatbots, content creation, automated reporting, and structured AI responses.
![Text Agent](./img/text-agent.webp)


## **Why Use the Text Agent?**

- **AI-Powered Content Generation:** Automate text creation for various use cases.
- **Customizable AI Responses:** Define system and user prompts for precise output.
- **Flexible Model Selection:** Choose from different LLM providers based on your needs.
- **Seamless Integration:** Connect with workflows for automated processing.


## **Key Features**

<details>
<summary>**Core Functionalities**</summary>

1. **Generative Model Selection** – Choose from multiple LLM providers and configure API credentials.  
2. **Customizable Prompts** – Define user and system prompts for tailored AI responses.  
3. **System Prompt Definition** – Guide AI behavior with context-aware instructions.  
4. **Advanced Properties Management** – Fine-tune outputs with additional configuration options.  

</details>

<details>
<summary>**Advantages**</summary>

1. **Flexibility** – Supports multiple LLMs, enabling diverse AI-powered applications.  
2. **User-Friendly Interface** – Easily configure prompt settings for quick deployment.  
3. **Enhanced Control** – Customize AI behavior through structured prompt templates.  
4. **Scalability** – Reuse and adapt prompt templates for various workflows.  

</details>


## **What Can I Build?**

- **Automated Content Generation** – AI-powered writing for blogs, social media, and marketing.  
- **Chatbots & Virtual Assistants** – Dynamic, context-aware conversational agents.  
- **Automated Reports & Summaries** – AI-driven data analysis and business intelligence reporting.  
- **Email & Message Drafting** – Smart communication tools for efficiency and personalization.  


## **How to Use the Text Agent?**

### **Creating a Text Agent via Flow Editor**
1. **Add a Text Agent Node** – Select the **Text Agent** from the node list.  
2. **Configure Prompts** – Define system-level and user prompts.  
3. **Select an LLM Model** – Choose an AI model for text generation.  
4. **Customize Output Settings** – Adjust properties for response formatting.  
5. **Connect & Deploy** – Integrate the Text Agent into your workflow and execute.  

### **Creating a Text Agent via Agent Dashboard**
1. **Go to the Agents Page** – Click **New Agent**.  
2. **Choose Text Agent** – Select from available agent types.  
3. **Configure Model & Prompts** – Set up LLM credentials and prompt templates.  
4. **Deploy & Integrate** – Save and start using the agent in your application.  


## **Configuration Options**

| **Parameter**        | **Description**                                        | **Example Value** |
|----------------------|--------------------------------------------------------|-------------------|
| **LLM Model**       | Selects the AI model for text generation.               | `GPT-4 Turbo` |
| **System Prompt**   | Guides AI behavior with a predefined instruction.       | `"Act as a marketing expert"` |
| **User Prompt**     | Defines user-specific input for response customization. | `"Generate an engaging blog intro"` |
| **Response Format** | Adjusts output style (structured, plain text, JSON).    | `JSON` |
| **Stop Words**      | Specifies words to terminate response generation.       | `"end"` |


## Output

#### `_meta`
- A nested object containing metadata about the processing of the text generation request.

  - **`prompt_tokens`**: Number of tokens in the input prompt.
  - **`completion_tokens`**: Number of tokens in the generated output.
  - **`total_tokens`**: Sum of `prompt_tokens` and `completion_tokens`.

  - **`prompt_tokens_details`**: Breakdown of token usage in the prompt.
    - **`cached_tokens`**: Tokens reused from cache.
    - **`audio_tokens`**: Tokens from audio input (if applicable).

  - **`completion_tokens_details`**: Breakdown of token usage in the generated output.
    - **`reasoning_tokens`**: Tokens used for reasoning.
    - **`audio_tokens`**: Tokens from audio output (if applicable).
    - **`accepted_prediction_tokens`**: Tokens from accepted predictions.
    - **`rejected_prediction_tokens`**: Tokens from rejected predictions.

  - **`model_name`**: Name of the AI model used for text generation.
  - **`model_provider`**: The provider or organization supplying the model.

#### `generatedResponse`
- A string containing the text output generated by the model based on the input prompt.


### Example Output

```json
{
    "_meta": {
      "prompt_tokens": 19,
      "completion_tokens": 212,
      "total_tokens": 231,
      "prompt_tokens_details": {
        "cached_tokens": 0,
        "audio_tokens": 0
      },
      "completion_tokens_details": {
        "reasoning_tokens": 0,
        "audio_tokens": 0,
        "accepted_prediction_tokens": 0,
        "rejected_prediction_tokens": 0
      },
      "model_name": "gpt-4-turbo",
      "model_provider": "openai"
    },
    "generatedResponse": "Response"
  }
```

## Troubleshooting

### Common Issues

| **Problem**                    | **Solution**                                                      |
| ------------------------------ | ----------------------------------------------------------------- |
| **Invalid API Key**            | Ensure the API key is correct and has not expired.                |
| **Dynamic Content Not Loaded** | Increase the `Wait for Page Load` time in the configuration.      |

### Debugging
1. Check Lamatic Flow logs for error details.
1. Verify API Key.